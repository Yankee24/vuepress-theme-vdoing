(window.webpackJsonp=window.webpackJsonp||[]).push([[266],{766:function(a,r,s){"use strict";s.r(r);var t=s(21),e=Object(t.a)({},(function(){var a=this,r=a.$createElement,s=a._self._c||r;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h4",{attrs:{id:"spark常见的面试题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#spark常见的面试题"}},[a._v("#")]),a._v(" Spark常见的面试题")]),a._v(" "),s("h5",{attrs:{id:"_1-通常来说-spark与mapreduce相比-spark运行效率更高。请说明效率更高来源于spark内置的哪些机制"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-通常来说-spark与mapreduce相比-spark运行效率更高。请说明效率更高来源于spark内置的哪些机制"}},[a._v("#")]),a._v(" 1. 通常来说，Spark与MapReduce相比，Spark运行效率更高。请说明效率更高来源于Spark内置的哪些机制？")]),a._v(" "),s("h5",{attrs:{id:"_2-hadoop和spark使用场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-hadoop和spark使用场景"}},[a._v("#")]),a._v(" 2. hadoop和spark使用场景？")]),a._v(" "),s("h5",{attrs:{id:"_3-spark如何保证宕机迅速恢复"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-spark如何保证宕机迅速恢复"}},[a._v("#")]),a._v(" 3. spark如何保证宕机迅速恢复?")]),a._v(" "),s("h5",{attrs:{id:"_4-hadoop和spark的相同点和不同点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-hadoop和spark的相同点和不同点"}},[a._v("#")]),a._v(" 4. hadoop和spark的相同点和不同点？")]),a._v(" "),s("h5",{attrs:{id:"_5-rdd持久化原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-rdd持久化原理"}},[a._v("#")]),a._v(" 5. RDD持久化原理？")]),a._v(" "),s("h5",{attrs:{id:"_6-checkpoint检查点机制"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6-checkpoint检查点机制"}},[a._v("#")]),a._v(" 6. checkpoint检查点机制？")]),a._v(" "),s("h5",{attrs:{id:"_7-checkpoint和持久化机制的区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7-checkpoint和持久化机制的区别"}},[a._v("#")]),a._v(" 7. checkpoint和持久化机制的区别？")]),a._v(" "),s("h5",{attrs:{id:"_8-rdd机制理解吗"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8-rdd机制理解吗"}},[a._v("#")]),a._v(" 8. RDD机制理解吗？")]),a._v(" "),s("h5",{attrs:{id:"_9-spark-streaming以及基本工作原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9-spark-streaming以及基本工作原理"}},[a._v("#")]),a._v(" 9. Spark streaming以及基本工作原理？")]),a._v(" "),s("h5",{attrs:{id:"_10-dstream以及基本工作原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_10-dstream以及基本工作原理"}},[a._v("#")]),a._v(" 10. DStream以及基本工作原理？")]),a._v(" "),s("h5",{attrs:{id:"_11-spark有哪些组件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_11-spark有哪些组件"}},[a._v("#")]),a._v(" 11. spark有哪些组件？")]),a._v(" "),s("h5",{attrs:{id:"_12-spark工作机制"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12-spark工作机制"}},[a._v("#")]),a._v(" 12. spark工作机制？")]),a._v(" "),s("h5",{attrs:{id:"_13-说下宽依赖和窄依赖"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_13-说下宽依赖和窄依赖"}},[a._v("#")]),a._v(" 13. 说下宽依赖和窄依赖？")]),a._v(" "),s("h5",{attrs:{id:"_14-spark主备切换机制原理知道吗"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_14-spark主备切换机制原理知道吗"}},[a._v("#")]),a._v(" 14. Spark主备切换机制原理知道吗？")]),a._v(" "),s("h5",{attrs:{id:"_15-spark解决了hadoop的哪些问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_15-spark解决了hadoop的哪些问题"}},[a._v("#")]),a._v(" 15. spark解决了hadoop的哪些问题？")]),a._v(" "),s("h5",{attrs:{id:"_16-数据倾斜的产生和解决办法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_16-数据倾斜的产生和解决办法"}},[a._v("#")]),a._v(" 16. 数据倾斜的产生和解决办法？")]),a._v(" "),s("h5",{attrs:{id:"_17-你用sparksql处理的时候-处理过程中用的dataframe还是直接写的sql-为什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_17-你用sparksql处理的时候-处理过程中用的dataframe还是直接写的sql-为什么"}},[a._v("#")]),a._v(" 17. 你用sparksql处理的时候， 处理过程中用的dataframe还是直接写的sql？为什么？")]),a._v(" "),s("h5",{attrs:{id:"_18-rdd中reducebykey与groupbykey哪个性能好-为什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_18-rdd中reducebykey与groupbykey哪个性能好-为什么"}},[a._v("#")]),a._v(" 18. RDD中reduceBykey与groupByKey哪个性能好，为什么？")]),a._v(" "),s("h5",{attrs:{id:"_19-spark-master-ha主从切换过程不会影响到集群已有作业的运行-为什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_19-spark-master-ha主从切换过程不会影响到集群已有作业的运行-为什么"}},[a._v("#")]),a._v(" 19. Spark master HA主从切换过程不会影响到集群已有作业的运行，为什么？")]),a._v(" "),s("h5",{attrs:{id:"_20-spark-master使用zookeeper进行ha-有哪些源数据保存到zookeeper里面"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_20-spark-master使用zookeeper进行ha-有哪些源数据保存到zookeeper里面"}},[a._v("#")]),a._v(" 20. spark master使用zookeeper进行ha，有哪些源数据保存到Zookeeper里面？")])])}),[],!1,null,null,null);r.default=e.exports}}]);